{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert markdown comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(line):\n",
    "    example_defaults = [[0.], [0.], [0.], [0.], [0]]\n",
    "    parsed_line = tf.decode_csv(line, example_defaults)\n",
    "    features = tf.reshape(parsed_line[:-1], shape = ((4,)))\n",
    "    labels = tf.reshape(parsed_line[-1], shape = (()))\n",
    "    return features, labels   \n",
    "\n",
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels = y, logits = y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables) # returns the gradient of the loss function with respect to all the model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation = \"relu\", input_shape = (4,)),\n",
    "    tf.keras.layers.Dense(10, activation = \"relu\"),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname = os.path.basename(train_dataset_url), origin=train_dataset_url)\n",
    "\n",
    "train_dataset = tf.data.TextLineDataset(train_dataset_fp)\n",
    "\n",
    "train_dataset = train_dataset.skip(1)             # skip the first header row\n",
    "train_dataset = train_dataset.map(parse_csv)      # parse each row\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)  # randomize\n",
    "train_dataset = train_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = list(train_dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=246, shape=(32, 3), dtype=float32, numpy=\n",
       "array([[1.9999787, 1.9538559, 1.9227166],\n",
       "       [1.9997761, 1.9317652, 1.8262267],\n",
       "       [1.9998621, 1.8904272, 1.8117819],\n",
       "       [1.9999994, 1.9835274, 1.9038116],\n",
       "       [1.9999663, 1.9940877, 1.3847582],\n",
       "       [1.9995071, 1.9392292, 1.5699806],\n",
       "       [1.9995978, 1.955271 , 1.7002175],\n",
       "       [1.9994366, 1.975436 , 1.4686047],\n",
       "       [1.9999927, 1.9510083, 1.9061899],\n",
       "       [1.999969 , 1.9464321, 1.9528457],\n",
       "       [1.9999958, 1.913749 , 1.9717603],\n",
       "       [1.9999821, 1.9610052, 1.8669156],\n",
       "       [1.9983909, 1.9742976, 1.462902 ],\n",
       "       [1.9999709, 1.9975294, 1.2071185],\n",
       "       [1.9997008, 1.9918481, 1.2521313],\n",
       "       [1.9998415, 1.89848  , 1.8287635],\n",
       "       [1.9999628, 1.9036245, 1.9186908],\n",
       "       [1.9988068, 1.9684327, 1.5191865],\n",
       "       [1.9996684, 1.9618807, 1.8072703],\n",
       "       [1.9984097, 1.9679722, 1.4764254],\n",
       "       [1.999956 , 1.9395852, 1.7995771],\n",
       "       [1.9999458, 1.9555118, 1.9226637],\n",
       "       [1.9999006, 1.9573114, 1.6995344],\n",
       "       [1.9983433, 1.9759465, 1.330253 ],\n",
       "       [1.9988365, 1.9825401, 1.252698 ],\n",
       "       [1.9999799, 1.9433686, 1.8989544],\n",
       "       [1.9979154, 1.9728847, 1.3848898],\n",
       "       [1.9999782, 1.9017938, 1.90284  ],\n",
       "       [1.9999988, 1.8494318, 1.9866774],\n",
       "       [1.9995475, 1.9264141, 1.7901834],\n",
       "       [1.9999967, 1.9618737, 1.9585443],\n",
       "       [1.9992567, 1.9017307, 1.7478554]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.erfc(model(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.253, Accuracy: 3.333%\n",
      "Epoch 050: Loss: 0.418, Accuracy: 92.500%\n",
      "Epoch 100: Loss: 0.221, Accuracy: 96.667%\n",
      "Epoch 150: Loss: 0.153, Accuracy: 97.500%\n",
      "Epoch 200: Loss: 0.120, Accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tfe.metrics.Mean()\n",
    "    epoch_accuracy = tfe.metrics.Accuracy()\n",
    "    \n",
    "    for x, y in train_dataset:\n",
    "        grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "        epoch_loss_avg(loss(model, x, y))\n",
    "        epoch_accuracy(tf.argmax(model(x), axis = 1, output_type = tf.int32), y)\n",
    "        \n",
    "    train_loss_results.append(epoch_loss_avg.result())\n",
    "    train_accuracy_results.append(epoch_accuracy.result())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch, epoch_loss_avg.result(), epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_url = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "test_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(test_dataset_url),origin=test_dataset_url)\n",
    "\n",
    "test_dataset = tf.data.TextLineDataset(test_dataset_fp)\n",
    "\n",
    "test_dataset = test_dataset.skip(1)             # skip the first header row\n",
    "test_dataset = test_dataset.map(parse_csv)      # parse each row\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1000)  # randomize\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "for x,y in test_dataset:\n",
    "    prediction = tf.argmax(model(x), axis = 1, output_type = tf.int32)\n",
    "    test_accuracy(prediction, y)\n",
    "    \n",
    "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0 prediction: Iris setosa\n",
      "Example 1 prediction: Iris versicolor\n",
      "Example 2 prediction: Iris virginica\n"
     ]
    }
   ],
   "source": [
    "class_ids = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]\n",
    "\n",
    "predict_dataset = tf.convert_to_tensor([\n",
    "    [5.1, 3.3, 1.7, 0.5,],\n",
    "    [5.9, 3.0, 4.2, 1.5,],\n",
    "    [6.9, 3.1, 5.4, 2.1]\n",
    "])\n",
    "\n",
    "predictions = model(predict_dataset)\n",
    "\n",
    "for i, logits in enumerate(predictions):\n",
    "    class_idx = tf.argmax(logits).numpy()\n",
    "    name = class_ids[class_idx]\n",
    "    print(\"Example {} prediction: {}\".format(i, name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TF)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
